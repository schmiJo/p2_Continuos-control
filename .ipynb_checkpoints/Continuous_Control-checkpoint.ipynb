{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous Control\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, you will learn how to use the Unity ML-Agents environment for the second project of the [Deep Reinforcement Learning Nanodegree](https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893) program.\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "We begin by importing the necessary packages.  If the code cell below returns an error, please revisit the project instructions to double-check that you have installed [Unity ML-Agents](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Installation.md) and [NumPy](http://www.numpy.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will start the environment!  **_Before running the code cell below_**, change the `file_name` parameter to match the location of the Unity environment that you downloaded.\n",
    "\n",
    "- **Mac**: `\"path/to/Reacher.app\"`\n",
    "- **Windows** (x86): `\"path/to/Reacher_Windows_x86/Reacher.exe\"`\n",
    "- **Windows** (x86_64): `\"path/to/Reacher_Windows_x86_64/Reacher.exe\"`\n",
    "- **Linux** (x86): `\"path/to/Reacher_Linux/Reacher.x86\"`\n",
    "- **Linux** (x86_64): `\"path/to/Reacher_Linux/Reacher.x86_64\"`\n",
    "- **Linux** (x86, headless): `\"path/to/Reacher_Linux_NoVis/Reacher.x86\"`\n",
    "- **Linux** (x86_64, headless): `\"path/to/Reacher_Linux_NoVis/Reacher.x86_64\"`\n",
    "\n",
    "For instance, if you are using a Mac, then you downloaded `Reacher.app`.  If this file is in the same folder as the notebook, then the line below should appear as follows:\n",
    "```\n",
    "env = UnityEnvironment(file_name=\"Reacher.app\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\tgoal_speed -> 1.0\n",
      "\t\tgoal_size -> 5.0\n",
      "Unity brain name: ReacherBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 33\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name='Reacher.app')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "In this environment, a double-jointed arm can move to target locations. A reward of `+0.1` is provided for each step that the agent's hand is in the goal location. Thus, the goal of your agent is to maintain its position at the target location for as many time steps as possible.\n",
    "\n",
    "The observation space consists of `33` variables corresponding to position, rotation, velocity, and angular velocities of the arm.  Each action is a vector with four numbers, corresponding to torque applicable to two joints.  Every entry in the action vector must be a number between `-1` and `1`.\n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 1\n",
      "Size of each action: 4\n",
      "There are 1 agents. Each observes a state with length: 33\n",
      "The state for the first agent looks like: [ 0.00000000e+00 -4.00000000e+00  0.00000000e+00  1.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -4.37113883e-08  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00 -1.00000000e+01  0.00000000e+00\n",
      "  1.00000000e+00 -0.00000000e+00 -0.00000000e+00 -4.37113883e-08\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  5.75471878e+00 -1.00000000e+00\n",
      "  5.55726671e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      " -1.68164849e-01]\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents\n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take Random Actions in the Environment\n",
    "\n",
    "In the next code cell, you will learn how to use the Python API to control the agent and receive feedback from the environment.\n",
    "\n",
    "Once this cell is executed, you will watch the agent's performance, if it selects an action at random with each time step.  A window should pop up that allows you to observe the agent, as it moves through the environment.  \n",
    "\n",
    "Of course, as part of the project, you'll have to change the code so that the agent is able to use its experience to gradually choose better actions when interacting with the environment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-2466012015f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_agents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# select an action (for each agent)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m                  \u001b[0;31m# all actions between -1 and 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0menv_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbrain_name\u001b[0m\u001b[0;34m]\u001b[0m          \u001b[0;31m# send all actions to tne environment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mnext_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvector_observations\u001b[0m         \u001b[0;31m# get next state (for each agent)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mrewards\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrewards\u001b[0m                         \u001b[0;31m# get reward (for each agent)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/drlnd/lib/python3.6/site-packages/unityagents/environment.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, vector_action, memory, text_action)\u001b[0m\n\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m             outputs = self.communicator.exchange(\n\u001b[0;32m--> 369\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate_step_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector_action\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_action\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m             )\n\u001b[1;32m    371\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/drlnd/lib/python3.6/site-packages/unityagents/rpc_communicator.py\u001b[0m in \u001b[0;36mexchange\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munity_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCopyFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munity_to_external\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent_conn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munity_to_external\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent_conn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/drlnd/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_ForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetbuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/drlnd/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"!i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxsize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/drlnd/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mremaining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "env_info = env.reset(train_mode=False)[brain_name]     # reset the environment    \n",
    "states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "while True:\n",
    "    actions = np.random.randn(num_agents, action_size) # select an action (for each agent)\n",
    "    actions = np.clip(actions, -1, 1)                  # all actions between -1 and 1\n",
    "    env_info = env.step(actions)[brain_name]          # send all actions to tne environment\n",
    "    next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "    rewards = env_info.rewards                         # get reward (for each agent)\n",
    "    dones = env_info.local_done                        # see if episode finished\n",
    "    scores += env_info.rewards                         # update the score (for each agent)\n",
    "    states = next_states                               # roll over states to next time step\n",
    "    if np.any(dones):                                  # exit loop if episode finished\n",
    "        break\n",
    "print('Total score (averaged over agents) this episode: {}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, you can close the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. It's Your Turn!\n",
    "\n",
    "Now it's your turn to train your own agent to solve the environment!  When training the environment, set `train_mode=True`, so that the line for resetting the environment looks like the following:\n",
    "```python\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\tgoal_speed -> 1.0\n",
      "\t\tgoal_size -> 5.0\n",
      "Unity brain name: ReacherBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 33\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 1\n",
      "Size of each action: 4\n",
      "There are 1 agents. Each observes a state with length: 33\n",
      "The state for the first agent looks like: [ 0.00000000e+00 -4.00000000e+00  0.00000000e+00  1.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -4.37113883e-08  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00 -1.00000000e+01  0.00000000e+00\n",
      "  1.00000000e+00 -0.00000000e+00 -0.00000000e+00 -4.37113883e-08\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  5.75471878e+00 -1.00000000e+00\n",
      "  5.55726671e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      " -1.68164849e-01]\n"
     ]
    }
   ],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "\n",
    "env = UnityEnvironment(file_name='Reacher.app')\n",
    "\n",
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]\n",
    "\n",
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents\n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make all important imorts and create agent\n",
    "\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "from agent import Agent\n",
    "\n",
    "\n",
    "agent = Agent(state_size=33, action_size=4)\n",
    "agent.restore_critic_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action_evaluation\n",
      "0.0008926796913146973\n",
      "action_evaluation\n",
      "0.0010912883281707763\n",
      "action_evaluation\n",
      "0.0010174432396888736\n",
      "action_evaluation\n",
      "0.0007551735639572139\n",
      "action_evaluation\n",
      "0.00034466683864593523\n",
      "action_evaluation\n",
      "6.12527132034307e-05\n",
      "action_evaluation\n",
      "-0.00012159645557403582\n",
      "action_evaluation\n",
      "-0.00021786689758300764\n",
      "action_evaluation\n",
      "-0.00029431283473968506\n",
      "action_evaluation\n",
      "-0.00035459816455841054\n",
      "action_evaluation\n",
      "-0.0003473842144012451\n",
      "action_evaluation\n",
      "-0.00035066336393356403\n",
      "action_evaluation\n",
      "-0.0004054865241050719\n",
      "action_evaluation\n",
      "-0.00036590516567230197\n",
      "action_evaluation\n",
      "-0.0002910673618316652\n",
      "action_evaluation\n",
      "-0.0002043658494949338\n",
      "action_evaluation\n",
      "-0.00023565590381622323\n",
      "action_evaluation\n",
      "-0.0002634745836257936\n",
      "action_evaluation\n",
      "-0.0002246665954589843\n",
      "action_evaluation\n",
      "-0.0002672931551933287\n",
      "action_evaluation\n",
      "-0.00029793202877044685\n",
      "action_evaluation\n",
      "-0.00034475386142730725\n",
      "action_evaluation\n",
      "-0.0001319310069084166\n",
      "action_evaluation\n",
      "0.000528857707977295\n",
      "action_evaluation\n",
      "0.0006739610433578488\n",
      "action_evaluation\n",
      "0.0004411238431930543\n",
      "action_evaluation\n",
      "0.00033130675554275506\n",
      "action_evaluation\n",
      "0.0002670925855636601\n",
      "action_evaluation\n",
      "0.00018426090478897064\n",
      "action_evaluation\n",
      "7.502138614654506e-05\n",
      "action_evaluation\n",
      "8.180916309356683e-05\n",
      "action_evaluation\n",
      "0.00010827213525772122\n",
      "action_evaluation\n",
      "0.000186778008937836\n",
      "action_evaluation\n",
      "0.00015130847692489645\n",
      "action_evaluation\n",
      "6.383240222930867e-05\n",
      "action_evaluation\n",
      "-1.3360381126399992e-06\n",
      "action_evaluation\n",
      "-2.003937959671031e-05\n",
      "action_evaluation\n",
      "0.0001054418087005609\n",
      "action_evaluation\n",
      "0.0002552971243858339\n",
      "action_evaluation\n",
      "0.00033703327178955054\n",
      "action_evaluation\n",
      "0.00034580349922180235\n",
      "action_evaluation\n",
      "0.00042597949504852295\n",
      "action_evaluation\n",
      "0.000404866337776184\n",
      "action_evaluation\n",
      "0.00011307716369628878\n",
      "action_evaluation\n",
      "-0.000538619756698608\n",
      "action_evaluation\n",
      "-0.0009164929389953612\n",
      "action_evaluation\n",
      "-0.0007633194327354431\n",
      "action_evaluation\n",
      "-0.0006087532639503486\n",
      "action_evaluation\n",
      "-0.0003465944528579707\n",
      "action_evaluation\n",
      "-0.00016814649105072015\n",
      "action_evaluation\n",
      "-0.00010141372680664076\n",
      "action_evaluation\n",
      "3.919363021850572e-05\n",
      "action_evaluation\n",
      "4.42767143249514e-05\n",
      "action_evaluation\n",
      "1.579523086544382e-07\n",
      "action_evaluation\n",
      "-1.1827051639556625e-05\n",
      "action_evaluation\n",
      "-6.35057687759389e-06\n",
      "action_evaluation\n",
      "-3.5935342311859374e-05\n",
      "action_evaluation\n",
      "-1.6722381114959734e-05\n",
      "action_evaluation\n",
      "3.753125667572011e-05\n",
      "action_evaluation\n",
      "0.00013563007116317765\n",
      "action_evaluation\n",
      "0.0003440949320793153\n",
      "action_evaluation\n",
      "6.429731845855732e-05\n",
      "action_evaluation\n",
      "-7.063090801239045e-05\n",
      "action_evaluation\n",
      "0.00015476793050765974\n",
      "action_evaluation\n",
      "0.0002345433831214905\n",
      "action_evaluation\n",
      "3.3669471740722934e-05\n",
      "action_evaluation\n",
      "3.697276115417498e-05\n",
      "action_evaluation\n",
      "1.1527538299558465e-06\n",
      "action_evaluation\n",
      "0.00011178910732269256\n",
      "action_evaluation\n",
      "0.00016285300254821784\n",
      "action_evaluation\n",
      "0.00011689871549606327\n",
      "action_evaluation\n",
      "7.168173789978086e-05\n",
      "action_evaluation\n",
      "-4.534095525741619e-05\n",
      "action_evaluation\n",
      "-0.00012414574623107865\n",
      "action_evaluation\n",
      "1.9064545631409038e-06\n",
      "action_evaluation\n",
      "0.00016445815563201913\n",
      "action_evaluation\n",
      "0.0004801833629608154\n",
      "action_evaluation\n",
      "0.0005110785365104679\n",
      "action_evaluation\n",
      "0.0004563301801681517\n",
      "action_evaluation\n",
      "0.00046997010707855186\n",
      "action_evaluation\n",
      "0.00023036837577819838\n",
      "action_evaluation\n",
      "-0.00016358554363250788\n",
      "action_evaluation\n",
      "-0.0007589590549468986\n",
      "action_evaluation\n",
      "-0.0006407025456428529\n",
      "action_evaluation\n",
      "-0.000515896826982498\n",
      "action_evaluation\n",
      "-0.0005017650127410889\n",
      "action_evaluation\n",
      "-0.00023966193199157718\n",
      "action_evaluation\n",
      "-8.340656757354736e-05\n",
      "action_evaluation\n",
      "4.322782158851625e-05\n",
      "action_evaluation\n",
      "0.00011687487363815308\n",
      "action_evaluation\n",
      "0.00012000232934951784\n",
      "action_evaluation\n",
      "2.3595988750457764e-05\n",
      "action_evaluation\n",
      "2.4396479129791264e-05\n",
      "action_evaluation\n",
      "9.65563952922821e-05\n",
      "action_evaluation\n",
      "0.00023173362016677853\n",
      "action_evaluation\n",
      "0.00022657439112663266\n",
      "action_evaluation\n",
      "0.0003152984380722046\n",
      "action_evaluation\n",
      "0.00011270493268966675\n",
      "action_evaluation\n",
      "1.1974573135376009e-05\n",
      "action_evaluation\n",
      "-9.421050548553468e-05\n",
      "action_evaluation\n",
      "-0.00041141211986541745\n",
      "action_evaluation\n",
      "-0.0005936422944068908\n",
      "action_evaluation\n",
      "-0.0006769177317619323\n",
      "action_evaluation\n",
      "-0.000716369450092316\n",
      "action_evaluation\n",
      "-0.00043863415718078556\n",
      "action_evaluation\n",
      "0.000241545438766479\n",
      "action_evaluation\n",
      "0.00079835444688797\n",
      "action_evaluation\n",
      "0.0010535156726837161\n",
      "action_evaluation\n",
      "0.0009899653494358062\n",
      "action_evaluation\n",
      "0.0006220829486846924\n",
      "action_evaluation\n",
      "0.0004887859523296356\n",
      "action_evaluation\n",
      "0.00043389201164245605\n",
      "action_evaluation\n",
      "0.0003354370594024658\n",
      "action_evaluation\n",
      "0.00030116841197013855\n",
      "action_evaluation\n",
      "0.0003588639199733734\n",
      "action_evaluation\n",
      "0.0002040071785449982\n",
      "action_evaluation\n",
      "0.00014511838555335998\n",
      "action_evaluation\n",
      "0.00019235685467720032\n",
      "action_evaluation\n",
      "0.00019008398056030273\n",
      "action_evaluation\n",
      "0.0001677720248699189\n",
      "action_evaluation\n",
      "0.00020526111125946042\n",
      "action_evaluation\n",
      "0.00027904078364372254\n",
      "action_evaluation\n",
      "0.0002718614041805267\n",
      "action_evaluation\n",
      "0.00022429972887039185\n",
      "action_evaluation\n",
      "6.72820210456848e-05\n",
      "action_evaluation\n",
      "-0.00014424175024032592\n",
      "action_evaluation\n",
      "-0.0004688394069671631\n",
      "action_evaluation\n",
      "-0.0007182472944259643\n",
      "action_evaluation\n",
      "-0.0007530663907527923\n",
      "action_evaluation\n",
      "-0.0009462773799896241\n",
      "action_evaluation\n",
      "-0.000854284167289734\n",
      "action_evaluation\n",
      "-0.0006943243741989137\n",
      "action_evaluation\n",
      "-0.0004474717378616334\n",
      "action_evaluation\n",
      "-0.0002926719188690186\n",
      "action_evaluation\n",
      "0.00010181248188018827\n",
      "action_evaluation\n",
      "0.00015139460563659644\n",
      "action_evaluation\n",
      "2.4157166481018552e-05\n",
      "action_evaluation\n",
      "1.5290379524230888e-05\n",
      "action_evaluation\n",
      "-5.1897168159485e-05\n",
      "action_evaluation\n",
      "-0.00010052323341369629\n",
      "action_evaluation\n",
      "-8.243680000305162e-05\n",
      "action_evaluation\n",
      "-3.836393356323239e-05\n",
      "action_evaluation\n",
      "0.00010067820549011178\n",
      "action_evaluation\n",
      "1.905739307403627e-05\n",
      "action_evaluation\n",
      "-6.751716136932373e-05\n",
      "action_evaluation\n",
      "-0.00020213127136230538\n",
      "action_evaluation\n",
      "-0.00018749594688415548\n",
      "action_evaluation\n",
      "-1.9180774688721744e-05\n",
      "action_evaluation\n",
      "0.00015007257461547956\n",
      "action_evaluation\n",
      "0.00024976134300231864\n",
      "action_evaluation\n",
      "-4.856586456297718e-06\n",
      "action_evaluation\n",
      "-0.0001873791217803962\n",
      "action_evaluation\n",
      "4.607439041137695e-05\n",
      "action_evaluation\n",
      "5.775213241577225e-05\n",
      "action_evaluation\n",
      "0.00018141746520996052\n",
      "action_evaluation\n",
      "0.00021939158439636224\n",
      "action_evaluation\n",
      "0.00020130872726440568\n",
      "action_evaluation\n",
      "0.00019845724105834947\n",
      "action_evaluation\n",
      "0.00019089221954345613\n",
      "action_evaluation\n",
      "0.0001356017589569103\n",
      "action_evaluation\n",
      "0.00017335057258605936\n",
      "action_evaluation\n",
      "0.00020811378955840933\n",
      "action_evaluation\n",
      "0.00022957921028137276\n",
      "action_evaluation\n",
      "5.8066844940184506e-05\n",
      "action_evaluation\n",
      "-2.236366271972552e-05\n",
      "action_evaluation\n",
      "-0.00015693187713623075\n",
      "action_evaluation\n",
      "-0.0003811204433441153\n",
      "action_evaluation\n",
      "-0.00026240587234497084\n",
      "action_evaluation\n",
      "-3.1810998916624936e-05\n",
      "action_evaluation\n",
      "0.00021295666694640981\n",
      "action_evaluation\n",
      "0.0004900145530700693\n",
      "action_evaluation\n",
      "0.0006900429725646973\n",
      "action_evaluation\n",
      "-4.844069480895892e-05\n",
      "action_evaluation\n",
      "-0.00014627933502197286\n",
      "action_evaluation\n",
      "-3.993511199958111e-07\n",
      "action_evaluation\n",
      "-2.1455287933349124e-05\n",
      "action_evaluation\n",
      "-0.0001363372802734384\n",
      "action_evaluation\n",
      "-8.574724197387557e-05\n",
      "action_evaluation\n",
      "-4.814147949218882e-05\n",
      "action_evaluation\n",
      "-4.724383354186984e-05\n",
      "action_evaluation\n",
      "-2.5887489318846338e-05\n",
      "action_evaluation\n",
      "-1.0175704956054757e-05\n",
      "action_evaluation\n",
      "5.64217567443695e-06\n",
      "action_evaluation\n",
      "-0.00018541693687438958\n",
      "action_evaluation\n",
      "-0.00026638031005859347\n",
      "action_evaluation\n",
      "-0.00041045904159545815\n",
      "action_evaluation\n",
      "-0.00044886231422424337\n",
      "action_evaluation\n",
      "-0.00038005888462066574\n",
      "action_evaluation\n",
      "-0.00025010108947753906\n",
      "action_evaluation\n",
      "-0.00013447523117065402\n",
      "action_evaluation\n",
      "-0.00018404960632324198\n",
      "action_evaluation\n",
      "-0.000195342302322387\n",
      "action_evaluation\n",
      "-0.00034834504127502497\n",
      "action_evaluation\n",
      "-0.0004881751537322999\n",
      "action_evaluation\n",
      "-0.0005227184295654285\n",
      "action_evaluation\n",
      "-0.00014082431793212974\n",
      "action_evaluation\n",
      "6.848096847534256e-05\n",
      "action_evaluation\n",
      "0.00016708970069885185\n",
      "action_evaluation\n",
      "0.00022049903869628996\n",
      "action_evaluation\n",
      "0.000249489545822143\n",
      "action_evaluation\n",
      "0.00016941428184509208\n",
      "action_evaluation\n",
      "-1.1277198791502865e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action_evaluation\n",
      "-9.208321571350063e-05\n",
      "action_evaluation\n",
      "-0.00015362620353698633\n",
      "action_evaluation\n",
      "-0.00019260406494140715\n",
      "action_evaluation\n",
      "-0.00018857955932617167\n",
      "action_evaluation\n",
      "-0.00021910667419433594\n",
      "action_evaluation\n",
      "-0.0001751351356506347\n",
      "action_evaluation\n",
      "-0.00013156414031982415\n",
      "action_evaluation\n",
      "-3.2825469970703194e-05\n",
      "action_evaluation\n",
      "0.0002085804939270016\n",
      "action_evaluation\n",
      "0.000597963333129883\n",
      "action_evaluation\n",
      "0.000527079105377198\n",
      "action_evaluation\n",
      "0.00036654233932495103\n",
      "action_evaluation\n",
      "-9.122371673584047e-05\n",
      "action_evaluation\n",
      "-0.00022337079048156787\n",
      "action_evaluation\n",
      "-0.0002126264572143554\n",
      "action_evaluation\n",
      "-0.0006298196315765378\n",
      "action_evaluation\n",
      "-0.0005549311637878425\n",
      "action_evaluation\n",
      "-0.0004934096336364734\n",
      "action_evaluation\n",
      "-0.0003779160976409915\n",
      "action_evaluation\n",
      "-0.00023642063140869203\n",
      "action_evaluation\n",
      "-0.00016512989997863672\n",
      "action_evaluation\n",
      "-0.0002494120597839357\n",
      "action_evaluation\n",
      "-9.675502777099602e-05\n",
      "action_evaluation\n",
      "-8.319139480590827e-05\n",
      "action_evaluation\n",
      "-8.759737014770418e-05\n",
      "action_evaluation\n",
      "-5.2504539489744637e-05\n",
      "action_evaluation\n",
      "-6.638765335083112e-05\n",
      "action_evaluation\n",
      "-0.0005585098266601557\n",
      "action_evaluation\n",
      "-4.764795303344692e-05\n",
      "action_evaluation\n",
      "-0.00024733424186706467\n",
      "action_evaluation\n",
      "-0.00032458424568176415\n",
      "action_evaluation\n",
      "-0.00022852301597595104\n",
      "action_evaluation\n",
      "1.9059181213377727e-05\n",
      "action_evaluation\n",
      "0.00017174243927002043\n",
      "action_evaluation\n",
      "0.00026028871536254786\n",
      "action_evaluation\n",
      "0.0003402507305145276\n",
      "action_evaluation\n",
      "0.000352318286895751\n",
      "action_evaluation\n",
      "0.00020662426948547287\n",
      "action_evaluation\n",
      "2.2387504577637066e-05\n",
      "action_evaluation\n",
      "4.56881523132318e-05\n",
      "action_evaluation\n",
      "-8.77678394317627e-05\n",
      "action_evaluation\n",
      "-0.00034656524658203264\n",
      "action_evaluation\n",
      "-0.0004681265354156486\n",
      "action_evaluation\n",
      "-0.0005777418613433834\n",
      "action_evaluation\n",
      "-0.0006703829765319826\n",
      "action_evaluation\n",
      "-0.0006073820590972896\n",
      "action_evaluation\n",
      "-0.00041149258613586495\n",
      "action_evaluation\n",
      "-0.0001865148544311513\n",
      "action_evaluation\n",
      "4.0824413299559575e-05\n",
      "action_evaluation\n",
      "0.0002482914924621573\n",
      "action_evaluation\n",
      "0.0003134286403656001\n",
      "action_evaluation\n",
      "0.0002563273906707776\n",
      "action_evaluation\n",
      "0.00012638568878173793\n",
      "action_evaluation\n",
      "0.00015578389167785617\n",
      "action_evaluation\n",
      "7.223606109619217e-05\n",
      "action_evaluation\n",
      "4.165649414062528e-05\n",
      "action_evaluation\n",
      "4.9374103546141745e-05\n",
      "action_evaluation\n",
      "1.1379718780518341e-05\n",
      "action_evaluation\n",
      "-1.7830133438111184e-05\n",
      "action_evaluation\n",
      "-2.261519432067774e-05\n",
      "action_evaluation\n",
      "-5.415439605712877e-05\n",
      "action_evaluation\n",
      "-8.095979690551751e-05\n",
      "action_evaluation\n",
      "-0.00011440038681030315\n",
      "action_evaluation\n",
      "-0.00011987447738647482\n",
      "action_evaluation\n",
      "-7.39860534667968e-05\n",
      "action_evaluation\n",
      "9.068012237548745e-05\n",
      "action_evaluation\n",
      "0.0002653527259826663\n",
      "action_evaluation\n",
      "0.00039090633392334026\n",
      "action_evaluation\n",
      "0.0004686713218688965\n",
      "action_evaluation\n",
      "0.0004228711128234867\n",
      "action_evaluation\n",
      "0.0003686046600341799\n",
      "action_evaluation\n",
      "0.00021201491355895934\n",
      "action_evaluation\n",
      "0.00013796567916870076\n",
      "action_evaluation\n",
      "0.00017326116561889628\n",
      "action_evaluation\n",
      "0.00014112949371337946\n",
      "action_evaluation\n",
      "2.484560012817362e-05\n",
      "action_evaluation\n",
      "0.0001593089103698736\n",
      "action_evaluation\n",
      "0.0001080679893493662\n",
      "action_evaluation\n",
      "-8.002877235412618e-05\n",
      "action_evaluation\n",
      "-0.00010351181030273521\n",
      "action_evaluation\n",
      "-0.0002331829071044924\n",
      "action_evaluation\n",
      "-0.00019558668136596645\n",
      "action_evaluation\n",
      "-0.000241174697875976\n",
      "action_evaluation\n",
      "-0.0002580046653747562\n",
      "action_evaluation\n",
      "-0.00019120216369628885\n",
      "action_evaluation\n",
      "-7.293939590454109e-05\n",
      "action_evaluation\n",
      "-2.5864839553833147e-05\n",
      "action_evaluation\n",
      "6.486058235168415e-05\n",
      "action_evaluation\n",
      "0.0002642679214477535\n",
      "action_evaluation\n",
      "0.00027495265007019057\n",
      "action_evaluation\n",
      "0.00023869276046752964\n",
      "action_evaluation\n",
      "0.0001450490951538097\n",
      "action_evaluation\n",
      "0.000147178173065185\n",
      "action_evaluation\n",
      "0.0001342564821243293\n",
      "action_evaluation\n",
      "0.000128247141838074\n",
      "action_evaluation\n",
      "1.681685447692781e-05\n",
      "action_evaluation\n",
      "-1.697182655334417e-05\n",
      "action_evaluation\n",
      "4.4859051704405906e-05\n",
      "action_evaluation\n",
      "2.1639466285704873e-05\n",
      "action_evaluation\n",
      "4.145801067352399e-05\n",
      "action_evaluation\n",
      "8.476674556732143e-05\n",
      "action_evaluation\n",
      "0.00014454245567321888\n",
      "action_evaluation\n",
      "0.0001366728544235224\n",
      "action_evaluation\n",
      "0.00010646939277648981\n",
      "action_evaluation\n",
      "8.205890655517585e-05\n",
      "action_evaluation\n",
      "-0.00011307120323181177\n",
      "action_evaluation\n",
      "-0.00025408506393432683\n",
      "action_evaluation\n",
      "-0.00030804038047790513\n",
      "action_evaluation\n",
      "-0.00015006065368652205\n",
      "action_evaluation\n",
      "-7.871270179748459e-05\n",
      "action_evaluation\n",
      "2.254366874694831e-05\n",
      "action_evaluation\n",
      "3.1881332397461215e-05\n",
      "action_evaluation\n",
      "-1.8682479858398576e-05\n",
      "action_evaluation\n",
      "7.004976272583126e-05\n",
      "action_evaluation\n",
      "0.00010587215423583929\n",
      "action_evaluation\n",
      "0.00011753320693969754\n",
      "action_evaluation\n",
      "0.00012903571128845132\n",
      "action_evaluation\n",
      "0.00014796137809753446\n",
      "action_evaluation\n",
      "0.00017499446868896474\n",
      "action_evaluation\n",
      "0.00021448969841003467\n",
      "action_evaluation\n",
      "0.00025526642799377375\n",
      "action_evaluation\n",
      "0.00032636880874633775\n",
      "action_evaluation\n",
      "0.0003823983669281007\n",
      "action_evaluation\n",
      "0.00034508526325225785\n",
      "action_evaluation\n",
      "0.00023474872112274215\n",
      "action_evaluation\n",
      "6.812751293182404e-05\n",
      "action_evaluation\n",
      "0.00019670248031616183\n",
      "action_evaluation\n",
      "0.000290029048919678\n",
      "action_evaluation\n",
      "0.0005447196960449222\n",
      "action_evaluation\n",
      "0.000724090337753296\n",
      "action_evaluation\n",
      "0.0008120346069335938\n",
      "action_evaluation\n",
      "0.0007051074504852294\n",
      "action_evaluation\n",
      "0.00039980694651603694\n",
      "action_evaluation\n",
      "0.0002467525005340576\n",
      "action_evaluation\n",
      "9.110689163208032e-05\n",
      "action_evaluation\n",
      "-0.00012090474367141722\n",
      "action_evaluation\n",
      "-0.00022264540195465104\n",
      "action_evaluation\n",
      "-0.00023401409387588477\n",
      "action_evaluation\n",
      "-0.00022600948810577422\n",
      "action_evaluation\n",
      "-0.0001472845673561097\n",
      "action_evaluation\n",
      "-7.076710462570156e-05\n",
      "action_evaluation\n",
      "-0.00010725438594818117\n",
      "action_evaluation\n",
      "-0.00013602197170257567\n",
      "action_evaluation\n",
      "-0.0002559846639633178\n",
      "action_evaluation\n",
      "-0.00038478553295135526\n",
      "action_evaluation\n",
      "-0.00030364394187927263\n",
      "action_evaluation\n",
      "-0.00026192784309387197\n",
      "action_evaluation\n",
      "-0.00010592460632324191\n",
      "action_evaluation\n",
      "6.575942039489715e-05\n",
      "action_evaluation\n",
      "0.00031919598579406745\n",
      "action_evaluation\n",
      "0.00037779390811920176\n",
      "action_evaluation\n",
      "0.0003322488069534297\n",
      "action_evaluation\n",
      "0.0002355825901031493\n",
      "action_evaluation\n",
      "0.00015283346176147477\n",
      "action_evaluation\n",
      "7.665872573852511e-05\n",
      "action_evaluation\n",
      "2.8263330459594744e-05\n",
      "action_evaluation\n",
      "-8.116960525512713e-06\n",
      "action_evaluation\n",
      "-9.23550128936767e-05\n",
      "action_evaluation\n",
      "-0.00010160326957702652\n",
      "action_evaluation\n",
      "-6.163477897644029e-05\n",
      "action_evaluation\n",
      "-0.00021934688091278113\n",
      "action_evaluation\n",
      "-0.0001468241214752199\n",
      "action_evaluation\n",
      "-0.0001284211874008176\n",
      "action_evaluation\n",
      "-1.420497894287151e-05\n",
      "action_evaluation\n",
      "0.00023754060268402124\n",
      "action_evaluation\n",
      "0.0003322505950927733\n",
      "action_evaluation\n",
      "0.0003277897834777833\n",
      "action_evaluation\n",
      "0.0002967226505279541\n",
      "action_evaluation\n",
      "0.0002665251493453977\n",
      "action_evaluation\n",
      "0.00010372564196586614\n",
      "action_evaluation\n",
      "-6.097957491874679e-05\n",
      "action_evaluation\n",
      "-9.858250617980971e-05\n",
      "action_evaluation\n",
      "-3.0338764190673828e-05\n",
      "action_evaluation\n",
      "-1.940548419952391e-05\n",
      "action_evaluation\n",
      "-7.041007280349752e-05\n",
      "action_evaluation\n",
      "-9.210556745529183e-05\n",
      "action_evaluation\n",
      "-7.985025644302373e-05\n",
      "action_evaluation\n",
      "-0.0001384061574935913\n",
      "action_evaluation\n",
      "-9.084939956665065e-05\n",
      "action_evaluation\n",
      "6.556510925292969e-06\n",
      "action_evaluation\n",
      "9.007453918457187e-06\n",
      "action_evaluation\n",
      "2.6661157608031966e-05\n",
      "action_evaluation\n",
      "0.00012425720691680922\n",
      "action_evaluation\n",
      "4.7923922538757255e-05\n",
      "action_evaluation\n",
      "-0.00023901700973510747\n",
      "action_evaluation\n",
      "-0.0004938769340515135\n",
      "action_evaluation\n",
      "-0.000498677492141724\n",
      "action_evaluation\n",
      "-0.00042882561683654785\n",
      "action_evaluation\n",
      "-0.00035301566123962375\n",
      "action_evaluation\n",
      "-0.00029505372047424275\n",
      "action_evaluation\n",
      "-0.0002371948957443238\n",
      "action_evaluation\n",
      "-0.00011505961418151883\n",
      "action_evaluation\n",
      "-0.0001283341646194456\n",
      "action_evaluation\n",
      "-0.00018848955631256114\n",
      "action_evaluation\n",
      "-0.00014620423316955532\n",
      "action_evaluation\n",
      "-0.0003411412239074712\n",
      "action_evaluation\n",
      "-0.000372219681739807\n",
      "action_evaluation\n",
      "-0.00027566194534301824\n",
      "Episode 1\tavg Score: 0.00action_evaluation\n",
      "-7.411837577819824e-05\n",
      "action_evaluation\n",
      "-1.904845237731944e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action_evaluation\n",
      "4.8471689224243233e-05\n",
      "action_evaluation\n",
      "3.167390823364223e-05\n",
      "action_evaluation\n",
      "1.1682510375980032e-06\n",
      "action_evaluation\n",
      "-3.807783126831034e-05\n",
      "action_evaluation\n",
      "-8.138656616210951e-05\n",
      "action_evaluation\n",
      "-0.00012092351913452117\n",
      "action_evaluation\n",
      "-0.00015813589096069346\n",
      "action_evaluation\n",
      "-0.0001348972320556639\n",
      "action_evaluation\n",
      "-0.00011535286903381365\n",
      "action_evaluation\n",
      "-0.00010983169078826894\n",
      "action_evaluation\n",
      "-9.429931640624924e-05\n",
      "action_evaluation\n",
      "-8.631646633148332e-05\n",
      "action_evaluation\n",
      "-8.26948881149283e-05\n",
      "action_evaluation\n",
      "-7.372379302978543e-05\n",
      "action_evaluation\n",
      "-6.514012813568087e-05\n",
      "action_evaluation\n",
      "-5.974590778350802e-05\n",
      "action_evaluation\n",
      "-4.2632818222046454e-05\n",
      "action_evaluation\n",
      "-4.284739494323647e-05\n",
      "action_evaluation\n",
      "-3.1003952026367396e-05\n",
      "action_evaluation\n",
      "-1.9609928131103516e-05\n",
      "action_evaluation\n",
      "-1.2425184249877444e-05\n",
      "action_evaluation\n",
      "-1.4786124229429834e-05\n",
      "action_evaluation\n",
      "-1.1156201362610627e-05\n",
      "action_evaluation\n",
      "-1.4287233352660092e-05\n",
      "action_evaluation\n",
      "-1.994431018829436e-05\n",
      "action_evaluation\n",
      "-3.4393072128295274e-05\n",
      "action_evaluation\n",
      "-3.694057464599665e-05\n",
      "action_evaluation\n",
      "-4.7804117202758165e-05\n",
      "action_evaluation\n",
      "-4.109621047973695e-05\n",
      "action_evaluation\n",
      "-1.6344785690307687e-05\n",
      "action_evaluation\n",
      "1.9391179084778803e-05\n",
      "action_evaluation\n",
      "4.1990876197814386e-05\n",
      "action_evaluation\n",
      "5.074620246887235e-05\n",
      "action_evaluation\n",
      "4.1735172271727475e-05\n",
      "action_evaluation\n",
      "8.907318115234514e-06\n",
      "action_evaluation\n",
      "-2.808451652526814e-05\n",
      "action_evaluation\n",
      "-5.115389823913581e-05\n",
      "action_evaluation\n",
      "-6.913244724273716e-05\n",
      "action_evaluation\n",
      "-8.902490139007548e-05\n",
      "action_evaluation\n",
      "-0.00010546028614044287\n",
      "action_evaluation\n",
      "-0.00011263847351074101\n",
      "action_evaluation\n",
      "-8.949995040893541e-05\n",
      "action_evaluation\n",
      "-8.979916572570898e-05\n",
      "action_evaluation\n",
      "-8.817672729492104e-05\n",
      "action_evaluation\n",
      "-0.0001033425331115733\n",
      "action_evaluation\n",
      "-0.00010988116264343262\n",
      "action_evaluation\n",
      "-0.00010953187942504793\n",
      "action_evaluation\n",
      "-0.0001075553894042975\n",
      "action_evaluation\n",
      "-6.904244422912577e-05\n",
      "action_evaluation\n",
      "-2.536892890930148e-05\n",
      "action_evaluation\n",
      "2.524852752684714e-06\n",
      "action_evaluation\n",
      "4.6497583389282574e-05\n",
      "action_evaluation\n",
      "0.00010322451591491741\n",
      "action_evaluation\n",
      "0.00012524247169494636\n",
      "action_evaluation\n",
      "0.00011491417884826674\n",
      "action_evaluation\n",
      "0.00010695695877075209\n",
      "action_evaluation\n",
      "9.32860374450676e-05\n",
      "action_evaluation\n",
      "7.414460182189955e-05\n",
      "action_evaluation\n",
      "6.939828395843492e-05\n",
      "action_evaluation\n",
      "4.8701167106628834e-05\n",
      "action_evaluation\n",
      "4.234194755554227e-05\n",
      "action_evaluation\n",
      "3.297805786132892e-05\n",
      "action_evaluation\n",
      "5.7731270790100514e-05\n",
      "action_evaluation\n",
      "9.701848030090315e-05\n",
      "action_evaluation\n",
      "0.00014663517475128115\n",
      "action_evaluation\n",
      "0.00018711686134338396\n",
      "action_evaluation\n",
      "0.00015223920345306449\n",
      "action_evaluation\n",
      "0.00011220872402191093\n",
      "action_evaluation\n",
      "7.157325744628924e-05\n",
      "action_evaluation\n",
      "1.635551452636684e-05\n",
      "action_evaluation\n",
      "-2.6423931121826588e-05\n",
      "action_evaluation\n",
      "-5.914509296417198e-05\n",
      "action_evaluation\n",
      "-3.8186311721801966e-05\n",
      "action_evaluation\n",
      "-4.906952381134033e-05\n",
      "action_evaluation\n",
      "-6.366670131683315e-05\n",
      "action_evaluation\n",
      "-8.099317550659159e-05\n",
      "action_evaluation\n",
      "-6.0944557189941163e-05\n",
      "action_evaluation\n",
      "-7.254123687744102e-05\n",
      "action_evaluation\n",
      "-9.454846382141169e-05\n",
      "action_evaluation\n",
      "-9.816527366638197e-05\n",
      "action_evaluation\n",
      "-9.57679748535157e-05\n",
      "action_evaluation\n",
      "-4.998445510864206e-05\n",
      "action_evaluation\n",
      "3.532767295837385e-05\n",
      "action_evaluation\n",
      "0.00011469542980194116\n",
      "action_evaluation\n",
      "0.00016587793827056805\n",
      "action_evaluation\n",
      "9.956121444702152e-05\n",
      "action_evaluation\n",
      "0.00013167142868042003\n",
      "action_evaluation\n",
      "0.00020915985107421847\n",
      "action_evaluation\n",
      "0.00017721295356750485\n",
      "action_evaluation\n",
      "0.0001680898666381837\n",
      "action_evaluation\n",
      "0.00012211561203002898\n",
      "action_evaluation\n",
      "3.8583278656006276e-05\n",
      "action_evaluation\n",
      "1.3271570205688685e-05\n",
      "action_evaluation\n",
      "2.6810169219968275e-06\n",
      "action_evaluation\n",
      "7.428765296936014e-05\n",
      "action_evaluation\n",
      "0.00010035276412963864\n",
      "action_evaluation\n",
      "8.226513862609908e-05\n",
      "action_evaluation\n",
      "7.312715053558322e-05\n",
      "action_evaluation\n",
      "6.872951984405583e-05\n",
      "action_evaluation\n",
      "5.6591629981994455e-05\n",
      "action_evaluation\n",
      "0.00012268483638763414\n",
      "action_evaluation\n",
      "0.0002023693919181828\n",
      "action_evaluation\n",
      "0.00030618309974670375\n",
      "action_evaluation\n",
      "0.0003097951412200928\n",
      "action_evaluation\n",
      "0.00026105105876922646\n",
      "action_evaluation\n",
      "4.593431949615444e-05\n",
      "action_evaluation\n",
      "-5.754828453063965e-05\n",
      "action_evaluation\n",
      "4.391014575958266e-05\n",
      "action_evaluation\n",
      "4.1899085044860666e-05\n",
      "action_evaluation\n",
      "2.0782947540282787e-05\n",
      "action_evaluation\n",
      "-2.5240778923034737e-05\n",
      "action_evaluation\n",
      "-2.0723938941955705e-05\n",
      "action_evaluation\n",
      "-4.046082496643021e-05\n",
      "action_evaluation\n",
      "-6.248354911804217e-05\n",
      "action_evaluation\n",
      "-8.412480354309023e-05\n",
      "action_evaluation\n",
      "-0.0001585632562637329\n",
      "action_evaluation\n",
      "-0.00020893096923828205\n",
      "action_evaluation\n",
      "-0.00022758007049560568\n",
      "action_evaluation\n",
      "-0.0002355188131332401\n",
      "action_evaluation\n",
      "-0.00022757023572921725\n",
      "action_evaluation\n",
      "-0.00023946762084960972\n",
      "action_evaluation\n",
      "-0.00012621998786926242\n",
      "action_evaluation\n",
      "-8.922815322875803e-06\n",
      "action_evaluation\n",
      "1.9448995590210134e-05\n",
      "action_evaluation\n",
      "6.616115570071829e-08\n",
      "action_evaluation\n",
      "8.201241493225112e-05\n",
      "action_evaluation\n",
      "0.00012386143207550066\n",
      "action_evaluation\n",
      "0.0001556909084320067\n",
      "action_evaluation\n",
      "0.00011791944503784183\n",
      "action_evaluation\n",
      "0.0001343417167663577\n",
      "action_evaluation\n",
      "5.2202343940734725e-05\n",
      "action_evaluation\n",
      "7.3993206024169575e-06\n",
      "action_evaluation\n",
      "2.8477907180786063e-05\n",
      "action_evaluation\n",
      "0.0001092314720153812\n",
      "action_evaluation\n",
      "0.00021558105945587106\n",
      "action_evaluation\n",
      "0.0002772450447082525\n",
      "action_evaluation\n",
      "0.0002105563879013059\n",
      "action_evaluation\n",
      "0.00021341741085052508\n",
      "action_evaluation\n",
      "0.0002079653739929196\n",
      "action_evaluation\n",
      "0.0001151126623153689\n",
      "action_evaluation\n",
      "-0.00015261650085449238\n",
      "action_evaluation\n",
      "-0.00017303109169006367\n",
      "action_evaluation\n",
      "-0.0001571488380432127\n",
      "action_evaluation\n",
      "-0.00016529619693756098\n",
      "action_evaluation\n",
      "-0.00014524638652801567\n",
      "action_evaluation\n",
      "-0.000128800868988037\n",
      "action_evaluation\n",
      "-0.00010467588901519765\n",
      "action_evaluation\n",
      "-7.959306240081735e-05\n",
      "action_evaluation\n",
      "-7.237613201141382e-05\n",
      "action_evaluation\n",
      "-0.00010750591754913295\n",
      "action_evaluation\n",
      "-8.329927921295159e-05\n",
      "action_evaluation\n",
      "-7.029175758361834e-05\n",
      "action_evaluation\n",
      "-8.927941322326664e-05\n",
      "action_evaluation\n",
      "-8.138716220855696e-05\n",
      "action_evaluation\n",
      "-6.398797035217247e-05\n",
      "action_evaluation\n",
      "4.300475120544087e-06\n",
      "action_evaluation\n",
      "3.328382968902609e-05\n",
      "action_evaluation\n",
      "-9.279847145080705e-06\n",
      "action_evaluation\n",
      "2.4657249450683177e-05\n",
      "action_evaluation\n",
      "4.5205354690551654e-05\n",
      "action_evaluation\n",
      "7.768809795379635e-05\n",
      "action_evaluation\n",
      "0.00010703742504119922\n",
      "action_evaluation\n",
      "0.00010453939437866239\n",
      "action_evaluation\n",
      "7.546186447143517e-05\n",
      "action_evaluation\n",
      "4.283368587493924e-05\n",
      "action_evaluation\n",
      "4.1255950927733716e-05\n",
      "action_evaluation\n",
      "1.858353614807122e-05\n",
      "action_evaluation\n",
      "-5.936622619628386e-06\n",
      "action_evaluation\n",
      "-4.68492507934605e-06\n",
      "action_evaluation\n",
      "-2.685368061065667e-05\n",
      "action_evaluation\n",
      "-3.0255317687988628e-05\n",
      "action_evaluation\n",
      "2.5712251663208285e-05\n",
      "action_evaluation\n",
      "7.495403289794903e-05\n",
      "action_evaluation\n",
      "7.22008943557736e-05\n",
      "action_evaluation\n",
      "8.146345615386982e-05\n",
      "action_evaluation\n",
      "5.942523479461658e-05\n",
      "action_evaluation\n",
      "4.7223567962646415e-05\n",
      "action_evaluation\n",
      "3.580093383789059e-05\n",
      "action_evaluation\n",
      "4.754185676574679e-05\n",
      "action_evaluation\n",
      "8.85981321334839e-05\n",
      "action_evaluation\n",
      "8.072495460510276e-05\n",
      "action_evaluation\n",
      "9.823739528656015e-05\n",
      "action_evaluation\n",
      "0.00010527759790420529\n",
      "action_evaluation\n",
      "0.000111144483089447\n",
      "action_evaluation\n",
      "7.785677909851081e-05\n",
      "action_evaluation\n",
      "7.055699825286865e-05\n",
      "action_evaluation\n",
      "7.82573223114015e-05\n",
      "action_evaluation\n",
      "8.268117904663107e-05\n",
      "action_evaluation\n",
      "7.572770118713379e-05\n",
      "action_evaluation\n",
      "6.630122661590611e-05\n",
      "action_evaluation\n",
      "5.923300981521603e-05\n",
      "action_evaluation\n",
      "3.970205783843973e-05\n",
      "action_evaluation\n",
      "5.48356771469115e-05\n",
      "action_evaluation\n",
      "5.662918090820323e-05\n",
      "action_evaluation\n",
      "4.4117569923400775e-05\n",
      "action_evaluation\n",
      "3.5239458084106515e-05\n",
      "action_evaluation\n",
      "2.3261308670044067e-05\n",
      "action_evaluation\n",
      "1.9590258598327533e-05\n",
      "action_evaluation\n",
      "4.440695047378549e-05\n",
      "action_evaluation\n",
      "4.4228136539459315e-05\n",
      "action_evaluation\n",
      "4.260212182998651e-05\n",
      "action_evaluation\n",
      "4.1042566299438364e-05\n",
      "action_evaluation\n",
      "4.039466381072993e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action_evaluation\n",
      "3.451794385910044e-05\n",
      "action_evaluation\n",
      "2.2172033786773716e-05\n",
      "action_evaluation\n",
      "2.3245811462402344e-06\n",
      "action_evaluation\n",
      "1.4763176441192705e-05\n",
      "action_evaluation\n",
      "2.508968114852913e-05\n",
      "action_evaluation\n",
      "2.8521418571472073e-05\n",
      "action_evaluation\n",
      "3.397077322006212e-05\n",
      "action_evaluation\n",
      "3.1019151210784964e-05\n",
      "action_evaluation\n",
      "2.9482543468475246e-05\n",
      "action_evaluation\n",
      "3.124386072158821e-05\n",
      "action_evaluation\n",
      "3.531724214553842e-05\n",
      "action_evaluation\n",
      "3.74677777290344e-05\n",
      "action_evaluation\n",
      "3.4470856189727827e-05\n",
      "action_evaluation\n",
      "4.714846611022952e-05\n",
      "action_evaluation\n",
      "4.122436046600326e-05\n",
      "action_evaluation\n",
      "4.042714834213263e-05\n",
      "action_evaluation\n",
      "5.25492429733277e-05\n",
      "action_evaluation\n",
      "4.7180056571960406e-05\n",
      "action_evaluation\n",
      "3.413110971450806e-05\n",
      "action_evaluation\n",
      "2.9087662696838392e-05\n",
      "action_evaluation\n",
      "2.4905204772949227e-05\n",
      "action_evaluation\n",
      "2.331644296646115e-05\n",
      "action_evaluation\n",
      "1.7530024051666234e-05\n",
      "action_evaluation\n",
      "1.0139346122741734e-05\n",
      "action_evaluation\n",
      "6.739199161529571e-06\n",
      "action_evaluation\n",
      "1.8787384033203385e-06\n",
      "action_evaluation\n",
      "-4.407465457916242e-06\n",
      "action_evaluation\n",
      "-9.331703186035126e-06\n",
      "action_evaluation\n",
      "-2.5326013565063346e-06\n",
      "action_evaluation\n",
      "-9.863376617431723e-06\n",
      "action_evaluation\n",
      "-1.3417601585388218e-05\n",
      "action_evaluation\n",
      "-1.0878443717956556e-05\n",
      "action_evaluation\n",
      "-6.705522537231445e-06\n",
      "action_evaluation\n",
      "-7.107257843017565e-06\n",
      "action_evaluation\n",
      "1.966953277587457e-08\n",
      "action_evaluation\n",
      "2.969205379486006e-06\n",
      "action_evaluation\n",
      "-5.136728286743073e-06\n",
      "action_evaluation\n",
      "-2.498507499694826e-05\n",
      "action_evaluation\n",
      "-3.648459911346428e-05\n",
      "action_evaluation\n",
      "-0.00013015925884246832\n",
      "action_evaluation\n",
      "-0.00016331583261489872\n",
      "action_evaluation\n",
      "-0.00014810889959335325\n",
      "action_evaluation\n",
      "-0.0001290795207023619\n",
      "action_evaluation\n",
      "-0.00010980635881423966\n",
      "action_evaluation\n",
      "-0.00010460376739501948\n",
      "action_evaluation\n",
      "-0.00010555475950241094\n",
      "action_evaluation\n",
      "-7.666230201721193e-05\n",
      "action_evaluation\n",
      "-7.738322019577013e-05\n",
      "action_evaluation\n",
      "-6.535977125167848e-05\n",
      "action_evaluation\n",
      "-5.241155624389647e-05\n",
      "action_evaluation\n",
      "-4.5034289360046127e-05\n",
      "action_evaluation\n",
      "-2.1131634712219603e-05\n",
      "action_evaluation\n",
      "-4.881620407101543e-07\n",
      "action_evaluation\n",
      "1.3378262519836252e-05\n",
      "action_evaluation\n",
      "1.5753209590912195e-05\n",
      "action_evaluation\n",
      "-3.755390644073764e-06\n",
      "action_evaluation\n",
      "-1.3166666030881707e-06\n",
      "action_evaluation\n",
      "-3.921985626221744e-07\n",
      "action_evaluation\n",
      "-3.587305545806746e-06\n",
      "action_evaluation\n",
      "-8.083581924438199e-06\n",
      "action_evaluation\n",
      "-1.626074314117461e-05\n",
      "action_evaluation\n",
      "-2.5855302810668876e-05\n",
      "action_evaluation\n",
      "-6.423115730285617e-05\n",
      "action_evaluation\n",
      "-9.234726428985606e-05\n",
      "action_evaluation\n",
      "-0.00010050415992736818\n",
      "action_evaluation\n",
      "-0.00010777220129966738\n",
      "action_evaluation\n",
      "-0.00011146336793899526\n",
      "action_evaluation\n",
      "-0.00012005001306533833\n",
      "action_evaluation\n",
      "-0.00011905133724212638\n",
      "action_evaluation\n",
      "-8.53484869003298e-05\n",
      "action_evaluation\n",
      "-7.578372955322236e-05\n",
      "action_evaluation\n",
      "-6.428360939025879e-05\n",
      "action_evaluation\n",
      "-5.174487829208386e-05\n",
      "action_evaluation\n",
      "-4.380762577056892e-05\n",
      "action_evaluation\n",
      "-3.0118227005005056e-05\n",
      "action_evaluation\n",
      "-1.989960670471195e-05\n",
      "action_evaluation\n",
      "-5.367398262022365e-07\n",
      "action_evaluation\n",
      "1.575976610183709e-05\n",
      "action_evaluation\n",
      "2.3075044155120537e-05\n",
      "action_evaluation\n",
      "2.4780929088592807e-05\n",
      "action_evaluation\n",
      "-1.323223114013932e-06\n",
      "action_evaluation\n",
      "3.604590892792095e-06\n",
      "action_evaluation\n",
      "8.727312088012591e-06\n",
      "action_evaluation\n",
      "1.7670989036560128e-05\n",
      "action_evaluation\n",
      "2.6105642318725777e-05\n",
      "action_evaluation\n",
      "2.9570460319518644e-05\n",
      "action_evaluation\n",
      "4.3724179267883283e-05\n",
      "action_evaluation\n",
      "4.91994619369507e-05\n",
      "action_evaluation\n",
      "3.425061702728299e-05\n",
      "action_evaluation\n",
      "2.8590559959411517e-05\n",
      "action_evaluation\n",
      "1.3560056686401367e-05\n",
      "action_evaluation\n",
      "-3.0165910720825542e-06\n",
      "action_evaluation\n",
      "-1.892089843750014e-05\n",
      "action_evaluation\n",
      "-3.4062266349792116e-05\n",
      "action_evaluation\n",
      "-4.461407661437988e-05\n",
      "action_evaluation\n",
      "-5.796551704406738e-05\n",
      "action_evaluation\n",
      "-7.511138916015602e-05\n",
      "action_evaluation\n",
      "-8.557438850402815e-05\n",
      "action_evaluation\n",
      "-9.030938148498532e-05\n",
      "action_evaluation\n",
      "-9.238898754119866e-05\n",
      "action_evaluation\n",
      "-8.259057998657223e-05\n",
      "action_evaluation\n",
      "-7.894515991210957e-05\n",
      "action_evaluation\n",
      "-4.899740219116216e-05\n",
      "action_evaluation\n",
      "-3.523349761962906e-05\n",
      "action_evaluation\n",
      "-2.349436283111562e-05\n",
      "action_evaluation\n",
      "-1.771152019500741e-05\n",
      "action_evaluation\n",
      "-1.698493957519526e-05\n",
      "action_evaluation\n",
      "-1.2614727020263637e-05\n",
      "action_evaluation\n",
      "-8.025169372558559e-06\n",
      "action_evaluation\n",
      "-2.720475196838412e-05\n",
      "action_evaluation\n",
      "-4.1686892509460415e-05\n",
      "action_evaluation\n",
      "-5.9503912925720076e-05\n",
      "action_evaluation\n",
      "-5.4432153701782296e-05\n",
      "action_evaluation\n",
      "-5.1734447479247995e-05\n",
      "action_evaluation\n",
      "-5.091547966003425e-05\n",
      "action_evaluation\n",
      "-4.715800285339357e-05\n",
      "action_evaluation\n",
      "-4.212677478790264e-05\n",
      "action_evaluation\n",
      "-4.051268100738539e-05\n",
      "action_evaluation\n",
      "-4.8311948776244736e-05\n",
      "action_evaluation\n",
      "-5.598247051239033e-05\n",
      "action_evaluation\n",
      "-6.28238916397096e-05\n",
      "action_evaluation\n",
      "-6.883740425109872e-05\n",
      "action_evaluation\n",
      "-7.604122161865247e-05\n",
      "action_evaluation\n",
      "-6.73669576644895e-05\n",
      "action_evaluation\n",
      "-6.407797336578386e-05\n",
      "action_evaluation\n",
      "-6.698071956634521e-05\n",
      "action_evaluation\n",
      "-7.567822933197011e-05\n",
      "action_evaluation\n",
      "-7.591068744659465e-05\n",
      "action_evaluation\n",
      "-7.64334201812742e-05\n",
      "action_evaluation\n",
      "-5.805552005767791e-05\n",
      "action_evaluation\n",
      "-6.42561912536626e-05\n",
      "action_evaluation\n",
      "-6.341159343719455e-05\n",
      "action_evaluation\n",
      "-5.768239498138428e-05\n",
      "action_evaluation\n",
      "-5.1249265670776784e-05\n",
      "action_evaluation\n",
      "-6.003975868224855e-06\n",
      "action_evaluation\n",
      "1.4273524284362862e-05\n",
      "action_evaluation\n",
      "-3.4034252166751516e-06\n",
      "action_evaluation\n",
      "-1.761436462402368e-05\n",
      "action_evaluation\n",
      "-1.4488697052002057e-05\n",
      "action_evaluation\n",
      "-1.0368227958679026e-05\n",
      "action_evaluation\n",
      "-2.092123031616558e-06\n",
      "action_evaluation\n",
      "8.61763954162608e-06\n",
      "action_evaluation\n",
      "-1.464188098907436e-05\n",
      "action_evaluation\n",
      "-8.028745651245811e-07\n",
      "action_evaluation\n",
      "9.042024612426584e-06\n",
      "action_evaluation\n",
      "4.750013351440419e-05\n",
      "action_evaluation\n",
      "5.18113374710083e-05\n",
      "action_evaluation\n",
      "5.409002304077211e-05\n",
      "action_evaluation\n",
      "4.2521953582763325e-05\n",
      "action_evaluation\n",
      "3.535389900207516e-05\n",
      "action_evaluation\n",
      "2.7390718460083494e-05\n",
      "action_evaluation\n",
      "2.2879838943480613e-05\n",
      "action_evaluation\n",
      "1.771628856658998e-05\n",
      "action_evaluation\n",
      "1.0933876037597795e-05\n",
      "action_evaluation\n",
      "2.3573637008668727e-06\n",
      "action_evaluation\n",
      "-5.8239698410038e-06\n",
      "action_evaluation\n",
      "-8.23676586151137e-06\n",
      "action_evaluation\n",
      "-1.2437701225280658e-05\n",
      "action_evaluation\n",
      "-1.9371509552001953e-05\n",
      "action_evaluation\n",
      "-2.5219917297363004e-05\n",
      "action_evaluation\n",
      "-2.5911331176757882e-05\n",
      "action_evaluation\n",
      "-1.4166235923766986e-05\n",
      "action_evaluation\n",
      "-1.833975315094008e-05\n",
      "action_evaluation\n",
      "-2.134501934051517e-05\n",
      "action_evaluation\n",
      "-2.9940605163573768e-05\n",
      "action_evaluation\n",
      "-3.7813782691955775e-05\n",
      "action_evaluation\n",
      "-3.2911300659179896e-05\n",
      "action_evaluation\n",
      "-1.4790296554565395e-05\n",
      "action_evaluation\n",
      "-1.2744665145873572e-05\n",
      "action_evaluation\n",
      "-4.528760910034804e-06\n",
      "action_evaluation\n",
      "1.611948013305678e-05\n",
      "action_evaluation\n",
      "2.4775266647339075e-05\n",
      "action_evaluation\n",
      "5.534529685974083e-05\n",
      "action_evaluation\n",
      "8.450865745544475e-05\n",
      "action_evaluation\n",
      "0.00010199189186096188\n",
      "action_evaluation\n",
      "9.126484394073476e-05\n",
      "action_evaluation\n",
      "6.670713424682638e-05\n",
      "action_evaluation\n",
      "5.207121372222904e-05\n",
      "action_evaluation\n",
      "5.077600479125961e-05\n",
      "action_evaluation\n",
      "5.067825317382844e-05\n",
      "action_evaluation\n",
      "4.583358764648432e-05\n",
      "action_evaluation\n",
      "4.424870014190646e-05\n",
      "action_evaluation\n",
      "4.835605621337884e-05\n",
      "action_evaluation\n",
      "4.363805055618286e-05\n",
      "action_evaluation\n",
      "6.591856479644777e-05\n",
      "action_evaluation\n",
      "6.941199302673345e-05\n",
      "action_evaluation\n",
      "6.188213825225868e-05\n",
      "action_evaluation\n",
      "5.5342912673950195e-05\n",
      "action_evaluation\n",
      "6.063938140869101e-05\n",
      "action_evaluation\n",
      "5.725204944610632e-05\n",
      "action_evaluation\n",
      "3.9243698120117274e-05\n",
      "action_evaluation\n",
      "1.0907649993896484e-05\n",
      "action_evaluation\n",
      "5.350112915039184e-06\n",
      "action_evaluation\n",
      "1.1321306228637834e-05\n",
      "action_evaluation\n",
      "1.3687014579772793e-05\n",
      "Episode 2\tavg Score: 0.00action_evaluation\n",
      "-6.68838620185852e-05\n",
      "action_evaluation\n",
      "-5.648568272590635e-05\n",
      "action_evaluation\n",
      "-4.407241940498349e-05\n",
      "action_evaluation\n",
      "-3.996640443801883e-05\n",
      "action_evaluation\n",
      "-2.125889062881464e-05\n",
      "action_evaluation\n",
      "-2.9093027114868945e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action_evaluation\n",
      "1.2459456920623879e-05\n",
      "action_evaluation\n",
      "2.3713260889053275e-05\n",
      "action_evaluation\n",
      "3.569170832633977e-05\n",
      "action_evaluation\n",
      "3.061562776565549e-05\n",
      "action_evaluation\n",
      "2.848982810974124e-05\n",
      "action_evaluation\n",
      "2.7481168508529657e-05\n",
      "action_evaluation\n",
      "2.500250935554509e-05\n",
      "action_evaluation\n",
      "2.1457672119140625e-05\n",
      "action_evaluation\n",
      "1.7349421977996815e-05\n",
      "action_evaluation\n",
      "1.3367235660552998e-05\n",
      "action_evaluation\n",
      "1.0083615779876693e-05\n",
      "action_evaluation\n",
      "1.2771338224411006e-05\n",
      "action_evaluation\n",
      "6.848126649856563e-06\n",
      "action_evaluation\n",
      "4.933029413223283e-06\n",
      "action_evaluation\n",
      "3.982037305831903e-06\n",
      "action_evaluation\n",
      "6.715357303619383e-06\n",
      "action_evaluation\n",
      "7.0334970951080355e-06\n",
      "action_evaluation\n",
      "5.765259265899653e-06\n",
      "action_evaluation\n",
      "8.603483438491833e-06\n",
      "action_evaluation\n",
      "9.36523079872131e-06\n",
      "action_evaluation\n",
      "6.9004297256469716e-06\n",
      "action_evaluation\n",
      "8.474439382553088e-06\n",
      "action_evaluation\n",
      "5.967170000076305e-06\n",
      "action_evaluation\n",
      "6.702691316604607e-06\n",
      "action_evaluation\n",
      "7.714480161666884e-06\n",
      "action_evaluation\n",
      "8.349418640136714e-06\n",
      "action_evaluation\n",
      "8.603632450103761e-06\n",
      "action_evaluation\n",
      "6.511807441711426e-06\n",
      "action_evaluation\n",
      "6.11960887908936e-06\n",
      "action_evaluation\n",
      "5.792081356048581e-06\n",
      "action_evaluation\n",
      "5.270540714263913e-06\n",
      "action_evaluation\n",
      "4.605650901794439e-06\n",
      "action_evaluation\n",
      "3.841519355773922e-06\n",
      "action_evaluation\n",
      "2.999454736709594e-06\n",
      "action_evaluation\n",
      "-1.2651085853576674e-06\n",
      "action_evaluation\n",
      "-5.8114528655986886e-09\n",
      "action_evaluation\n",
      "2.321451902389526e-06\n",
      "action_evaluation\n",
      "1.645684242248536e-06\n",
      "action_evaluation\n",
      "8.359551429748522e-07\n",
      "action_evaluation\n",
      "2.551674842834476e-06\n",
      "action_evaluation\n",
      "3.159195184707638e-06\n",
      "action_evaluation\n",
      "1.160502433776857e-06\n",
      "action_evaluation\n",
      "-1.4603137969970703e-06\n",
      "action_evaluation\n",
      "-4.683583974838256e-06\n",
      "action_evaluation\n",
      "-8.10965895652771e-06\n",
      "action_evaluation\n",
      "-2.0308494567871095e-05\n",
      "action_evaluation\n",
      "-2.900898456573486e-05\n",
      "action_evaluation\n",
      "-3.120034933090211e-05\n",
      "action_evaluation\n",
      "-3.2720118761062614e-05\n",
      "action_evaluation\n",
      "-3.403663635253906e-05\n",
      "action_evaluation\n",
      "-3.701969981193543e-05\n",
      "action_evaluation\n",
      "-3.928959369659424e-05\n",
      "action_evaluation\n",
      "-3.5001486539840696e-05\n",
      "action_evaluation\n",
      "-3.5725086927413904e-05\n",
      "action_evaluation\n",
      "-3.249391913414003e-05\n",
      "action_evaluation\n",
      "-2.786889672279358e-05\n",
      "action_evaluation\n",
      "-2.3660212755203267e-05\n",
      "action_evaluation\n",
      "-1.904487609863284e-05\n",
      "action_evaluation\n",
      "-1.3951659202575666e-05\n",
      "action_evaluation\n",
      "-8.522123098373411e-06\n",
      "action_evaluation\n",
      "-2.988427877426191e-06\n",
      "action_evaluation\n",
      "5.481839179992637e-06\n",
      "action_evaluation\n",
      "4.714876413345389e-06\n",
      "action_evaluation\n",
      "6.587356328964229e-06\n",
      "action_evaluation\n",
      "6.396025419235223e-06\n",
      "action_evaluation\n",
      "8.143782615661628e-06\n",
      "action_evaluation\n",
      "9.67383384704591e-06\n",
      "action_evaluation\n",
      "1.1802911758422878e-05\n",
      "action_evaluation\n",
      "1.257315278053279e-05\n",
      "action_evaluation\n",
      "1.2521147727966291e-05\n",
      "action_evaluation\n",
      "1.369655132293701e-05\n",
      "action_evaluation\n",
      "1.4790892601013216e-05\n",
      "action_evaluation\n",
      "1.9553899765014618e-05\n",
      "action_evaluation\n",
      "2.025082707405088e-05\n",
      "action_evaluation\n",
      "2.0306855440139777e-05\n",
      "action_evaluation\n",
      "1.9985884428024313e-05\n",
      "action_evaluation\n",
      "1.927942037582397e-05\n",
      "action_evaluation\n",
      "1.813650131225587e-05\n",
      "action_evaluation\n",
      "1.691281795501709e-05\n",
      "action_evaluation\n",
      "1.5170276165008537e-05\n",
      "action_evaluation\n",
      "1.156046986579897e-05\n",
      "action_evaluation\n",
      "9.526759386062621e-06\n",
      "action_evaluation\n",
      "6.461143493652336e-06\n",
      "action_evaluation\n",
      "5.8445334434509315e-06\n",
      "action_evaluation\n",
      "5.779415369033819e-06\n",
      "action_evaluation\n",
      "4.151016473770137e-06\n",
      "action_evaluation\n",
      "2.4442374706268273e-06\n",
      "action_evaluation\n",
      "9.29236412048335e-07\n",
      "action_evaluation\n",
      "-2.3782253265379558e-07\n",
      "action_evaluation\n",
      "-1.7535686492919965e-06\n",
      "action_evaluation\n",
      "-3.8325786590576145e-06\n",
      "action_evaluation\n",
      "-3.0520558357238726e-06\n",
      "action_evaluation\n",
      "-1.1253356933593815e-06\n",
      "action_evaluation\n",
      "2.297461032867436e-06\n",
      "action_evaluation\n",
      "5.75318932533263e-06\n",
      "action_evaluation\n",
      "9.640902280807505e-06\n",
      "action_evaluation\n",
      "1.2978613376617425e-05\n",
      "action_evaluation\n",
      "1.501858234405517e-05\n",
      "action_evaluation\n",
      "1.777768135070801e-05\n",
      "action_evaluation\n",
      "1.9687116146087644e-05\n",
      "action_evaluation\n",
      "1.8173605203628542e-05\n",
      "action_evaluation\n",
      "1.8163323402404786e-05\n",
      "action_evaluation\n",
      "1.8736422061920168e-05\n",
      "action_evaluation\n",
      "1.5636980533599855e-05\n",
      "action_evaluation\n",
      "1.3039112091064453e-05\n",
      "action_evaluation\n",
      "1.0576099157333374e-05\n",
      "action_evaluation\n",
      "7.900744676589966e-06\n",
      "action_evaluation\n",
      "5.1261484622955355e-06\n",
      "action_evaluation\n",
      "1.9502639770507693e-06\n",
      "action_evaluation\n",
      "1.2908726930618299e-05\n",
      "action_evaluation\n",
      "2.7441829442977907e-05\n",
      "action_evaluation\n",
      "2.6520192623138424e-05\n",
      "action_evaluation\n",
      "2.8400421142578126e-05\n",
      "action_evaluation\n",
      "2.5775432586669898e-05\n",
      "action_evaluation\n",
      "2.0604729652404816e-05\n",
      "action_evaluation\n",
      "1.0707378387451137e-05\n",
      "action_evaluation\n",
      "5.339086055755659e-06\n",
      "action_evaluation\n",
      "-1.1680126190185549e-05\n",
      "action_evaluation\n",
      "-2.6029944419860842e-05\n",
      "action_evaluation\n",
      "-3.452822566032412e-05\n",
      "action_evaluation\n",
      "-3.319844603538513e-05\n",
      "action_evaluation\n",
      "-3.077536821365358e-05\n",
      "action_evaluation\n",
      "-2.958327531814574e-05\n",
      "action_evaluation\n",
      "-3.4733861684799205e-05\n",
      "action_evaluation\n",
      "-3.355070948600768e-05\n",
      "action_evaluation\n",
      "-4.302248358726502e-05\n",
      "action_evaluation\n",
      "-4.9916505813598635e-05\n",
      "action_evaluation\n",
      "-5.039006471633911e-05\n",
      "action_evaluation\n",
      "-4.9649626016616826e-05\n",
      "action_evaluation\n",
      "-4.754632711410522e-05\n",
      "action_evaluation\n",
      "-4.608437418937683e-05\n",
      "action_evaluation\n",
      "-4.5241415500640875e-05\n",
      "action_evaluation\n",
      "-3.967881202697753e-05\n",
      "action_evaluation\n",
      "-3.3903568983077996e-05\n",
      "action_evaluation\n",
      "-2.6876479387283293e-05\n",
      "action_evaluation\n",
      "-1.4772117137908938e-05\n",
      "action_evaluation\n",
      "1.2508779764175426e-05\n",
      "action_evaluation\n",
      "1.384168863296511e-05\n",
      "action_evaluation\n",
      "1.3627111911773682e-05\n",
      "action_evaluation\n",
      "1.2270808219909661e-05\n",
      "action_evaluation\n",
      "1.3677626848220817e-05\n",
      "action_evaluation\n",
      "1.4597177505493142e-05\n",
      "action_evaluation\n",
      "1.5015155076980585e-05\n",
      "action_evaluation\n",
      "1.4986097812652599e-05\n",
      "action_evaluation\n",
      "1.6240775585174555e-05\n",
      "action_evaluation\n",
      "1.6731917858123788e-05\n",
      "action_evaluation\n",
      "1.4462769031524657e-05\n",
      "action_evaluation\n",
      "1.0624080896377554e-05\n",
      "action_evaluation\n",
      "8.246302604675288e-06\n",
      "action_evaluation\n",
      "6.066709756851184e-06\n",
      "action_evaluation\n",
      "5.412846803665161e-06\n",
      "action_evaluation\n",
      "3.684759140014658e-06\n",
      "action_evaluation\n",
      "2.021342515945429e-06\n",
      "action_evaluation\n",
      "4.7281384468077963e-07\n",
      "action_evaluation\n",
      "-1.0433793067932194e-06\n",
      "action_evaluation\n",
      "-2.779513597488386e-06\n",
      "action_evaluation\n",
      "-6.8368017673492356e-06\n",
      "action_evaluation\n",
      "-3.7655234336852865e-06\n",
      "action_evaluation\n",
      "-1.9164383411407557e-06\n",
      "action_evaluation\n",
      "-3.097951412200787e-07\n",
      "action_evaluation\n",
      "2.5677680969238238e-06\n",
      "action_evaluation\n",
      "5.679428577423087e-06\n",
      "action_evaluation\n",
      "9.576529264450074e-06\n",
      "action_evaluation\n",
      "1.6487389802932723e-05\n",
      "action_evaluation\n",
      "2.889156341552736e-05\n",
      "action_evaluation\n",
      "1.1439323425292973e-05\n",
      "action_evaluation\n",
      "1.879692077636718e-05\n",
      "action_evaluation\n",
      "2.3408234119415285e-05\n",
      "action_evaluation\n",
      "3.35828959941864e-05\n",
      "action_evaluation\n",
      "4.299357533454895e-05\n",
      "action_evaluation\n",
      "5.149364471435546e-05\n",
      "action_evaluation\n",
      "3.349393606185914e-05\n",
      "action_evaluation\n",
      "2.8189569711685174e-05\n",
      "action_evaluation\n",
      "2.6733130216598493e-05\n",
      "action_evaluation\n",
      "2.8342157602310184e-05\n",
      "action_evaluation\n",
      "1.4670938253402726e-05\n",
      "action_evaluation\n",
      "6.2653422355651725e-06\n",
      "action_evaluation\n",
      "1.1351704597472917e-06\n",
      "action_evaluation\n",
      "-3.5779178142547423e-06\n",
      "action_evaluation\n",
      "-8.231699466705323e-06\n",
      "action_evaluation\n",
      "2.1152198314666585e-06\n",
      "action_evaluation\n",
      "1.9705444574356077e-05\n",
      "action_evaluation\n",
      "1.7437934875488278e-05\n",
      "action_evaluation\n",
      "3.6046206951141364e-05\n",
      "action_evaluation\n",
      "3.152549266815185e-05\n",
      "action_evaluation\n",
      "2.648770809173586e-05\n",
      "action_evaluation\n",
      "2.0877122879028333e-05\n",
      "action_evaluation\n",
      "1.2606084346771234e-05\n",
      "action_evaluation\n",
      "4.810988903045663e-06\n",
      "action_evaluation\n",
      "-1.538246870040887e-06\n",
      "action_evaluation\n",
      "-1.3096630573272727e-05\n",
      "action_evaluation\n",
      "-1.7024278640747064e-05\n",
      "action_evaluation\n",
      "-2.2567510604858392e-05\n",
      "action_evaluation\n",
      "-2.8472989797592122e-05\n",
      "action_evaluation\n",
      "-3.733679652214052e-05\n",
      "action_evaluation\n",
      "-4.075407981872557e-05\n",
      "action_evaluation\n",
      "-4.5304000377655046e-05\n",
      "action_evaluation\n",
      "-4.6270489692687986e-05\n",
      "action_evaluation\n",
      "-4.614710807800293e-05\n",
      "action_evaluation\n",
      "-4.4996738433837895e-05\n",
      "action_evaluation\n",
      "-4.2969584465026854e-05\n",
      "action_evaluation\n",
      "-4.0175169706344606e-05\n",
      "action_evaluation\n",
      "-3.626346588134765e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action_evaluation\n",
      "-3.2483041286468514e-05\n",
      "action_evaluation\n",
      "-2.6427507400512702e-05\n",
      "action_evaluation\n",
      "-2.2411942481994642e-05\n",
      "action_evaluation\n",
      "-1.9520968198776228e-05\n",
      "action_evaluation\n",
      "-1.7043799161911024e-05\n",
      "action_evaluation\n",
      "-1.4908313751220697e-05\n",
      "action_evaluation\n",
      "-9.397864341735844e-06\n",
      "action_evaluation\n",
      "3.7093460559845014e-06\n",
      "action_evaluation\n",
      "3.3517181873321577e-06\n",
      "action_evaluation\n",
      "-5.684792995452556e-07\n",
      "action_evaluation\n",
      "-7.912516593935057e-08\n",
      "action_evaluation\n",
      "-1.8537044525144533e-07\n",
      "action_evaluation\n",
      "-5.0067901611328125e-06\n",
      "action_evaluation\n",
      "-3.888010978698759e-06\n",
      "action_evaluation\n",
      "-2.633929252624488e-06\n",
      "action_evaluation\n",
      "-1.3297796249389887e-06\n",
      "action_evaluation\n",
      "3.1292438507058394e-08\n",
      "action_evaluation\n",
      "1.4416873455047607e-06\n",
      "action_evaluation\n",
      "2.9405951499938987e-06\n",
      "action_evaluation\n",
      "2.559125423431366e-06\n",
      "action_evaluation\n",
      "-1.5893578529357888e-06\n",
      "action_evaluation\n",
      "7.885694503784462e-07\n",
      "action_evaluation\n",
      "-2.3801624774932796e-06\n",
      "action_evaluation\n",
      "-1.365721225738526e-05\n",
      "action_evaluation\n",
      "-1.2666136026382477e-05\n",
      "action_evaluation\n",
      "-9.705275297164882e-06\n",
      "action_evaluation\n",
      "-6.435066461563143e-06\n",
      "action_evaluation\n",
      "2.547651529312151e-06\n",
      "action_evaluation\n",
      "5.932450294494614e-06\n",
      "action_evaluation\n",
      "-1.9680559635162323e-05\n",
      "action_evaluation\n",
      "-2.4273842573165917e-05\n",
      "action_evaluation\n",
      "-1.633167266845703e-05\n",
      "action_evaluation\n",
      "5.204379558563263e-06\n",
      "action_evaluation\n",
      "1.8634647130966176e-05\n",
      "action_evaluation\n",
      "2.118587493896482e-05\n",
      "action_evaluation\n",
      "2.745360136032106e-05\n",
      "action_evaluation\n",
      "3.3948123455047625e-05\n",
      "action_evaluation\n",
      "3.801822662353514e-05\n",
      "action_evaluation\n",
      "4.355281591415406e-05\n",
      "action_evaluation\n",
      "5.580782890319824e-05\n",
      "action_evaluation\n",
      "6.203517317771911e-05\n",
      "action_evaluation\n",
      "6.775781512260438e-05\n",
      "action_evaluation\n",
      "5.7621300220489497e-05\n",
      "action_evaluation\n",
      "2.923041582107545e-05\n",
      "action_evaluation\n",
      "2.947852015495301e-05\n",
      "action_evaluation\n",
      "3.154918551445007e-05\n",
      "action_evaluation\n",
      "1.949533820152282e-05\n",
      "action_evaluation\n",
      "7.452070713042974e-07\n",
      "action_evaluation\n",
      "3.692507743835818e-07\n",
      "action_evaluation\n",
      "2.3530423641204812e-05\n",
      "action_evaluation\n",
      "2.9063075780868576e-05\n",
      "action_evaluation\n",
      "2.607643604278563e-05\n",
      "action_evaluation\n",
      "2.2571682929992652e-05\n",
      "action_evaluation\n",
      "1.867264509201053e-05\n",
      "action_evaluation\n",
      "1.4389157295227042e-05\n",
      "action_evaluation\n",
      "1.619368791580197e-05\n",
      "action_evaluation\n",
      "1.764997839927675e-05\n",
      "action_evaluation\n",
      "1.1428892612457269e-05\n",
      "action_evaluation\n",
      "5.621612071990997e-06\n",
      "action_evaluation\n",
      "-1.2716650962829612e-06\n",
      "action_evaluation\n",
      "-1.1054277420043947e-05\n",
      "action_evaluation\n",
      "-1.594856381416322e-05\n",
      "action_evaluation\n",
      "-2.0115375518798802e-05\n",
      "action_evaluation\n",
      "-2.33978033065796e-05\n",
      "action_evaluation\n",
      "-2.5475025177001986e-05\n",
      "action_evaluation\n",
      "-2.5993734598159788e-05\n",
      "action_evaluation\n",
      "-2.587616443634034e-05\n",
      "action_evaluation\n",
      "-3.369837999343871e-05\n",
      "action_evaluation\n",
      "-3.241926431655882e-05\n",
      "action_evaluation\n",
      "-3.0772686004638684e-05\n",
      "action_evaluation\n",
      "-2.8910636901855467e-05\n",
      "action_evaluation\n",
      "-2.7033388614654545e-05\n",
      "action_evaluation\n",
      "-2.52494215965271e-05\n",
      "action_evaluation\n",
      "-2.3644715547561652e-05\n",
      "action_evaluation\n",
      "-2.0062476396560674e-05\n",
      "action_evaluation\n",
      "-1.8462538719177246e-05\n",
      "action_evaluation\n",
      "-1.7268657684326174e-05\n",
      "action_evaluation\n",
      "-1.7206817865371704e-05\n",
      "action_evaluation\n",
      "-1.690208911895752e-05\n",
      "action_evaluation\n",
      "-1.6678869724273684e-05\n",
      "action_evaluation\n",
      "-2.2295266389846796e-05\n",
      "action_evaluation\n",
      "-2.5752782821655284e-05\n",
      "action_evaluation\n",
      "-3.601983189582825e-05\n",
      "action_evaluation\n",
      "-3.17007303237915e-05\n",
      "action_evaluation\n",
      "-2.841442823410035e-05\n",
      "action_evaluation\n",
      "-2.5604069232940677e-05\n",
      "action_evaluation\n",
      "-2.1777898073196408e-05\n",
      "action_evaluation\n",
      "-1.8356889486312864e-05\n",
      "action_evaluation\n",
      "-1.5204101800918551e-05\n",
      "action_evaluation\n",
      "-1.1538416147232082e-05\n",
      "action_evaluation\n",
      "-6.748288869857827e-06\n",
      "action_evaluation\n",
      "-3.446191549301154e-06\n",
      "action_evaluation\n",
      "-7.717460393905637e-06\n",
      "action_evaluation\n",
      "-1.7959177494049035e-05\n",
      "action_evaluation\n",
      "-2.154126763343812e-05\n",
      "action_evaluation\n",
      "-1.8872022628784173e-05\n",
      "action_evaluation\n",
      "-5.524903535842902e-06\n",
      "action_evaluation\n",
      "-2.441406250000002e-06\n",
      "action_evaluation\n",
      "-1.8945336341857823e-06\n",
      "action_evaluation\n",
      "-9.100735187530541e-06\n",
      "action_evaluation\n",
      "-1.4749020338058485e-05\n",
      "action_evaluation\n",
      "-1.9749402999877884e-05\n",
      "action_evaluation\n",
      "-3.124445676803587e-05\n",
      "action_evaluation\n",
      "-1.8680095672607509e-06\n",
      "action_evaluation\n",
      "1.0411739349365252e-05\n",
      "action_evaluation\n",
      "1.6148388385772716e-05\n",
      "action_evaluation\n",
      "1.3327896595001195e-05\n",
      "action_evaluation\n",
      "1.5617609024047878e-05\n",
      "action_evaluation\n",
      "2.145856618881222e-05\n",
      "action_evaluation\n",
      "2.671808004379273e-05\n",
      "action_evaluation\n",
      "3.108352422714238e-05\n",
      "action_evaluation\n",
      "3.474742174148555e-05\n",
      "action_evaluation\n",
      "3.776267170906068e-05\n",
      "action_evaluation\n",
      "4.956826567649843e-05\n",
      "action_evaluation\n",
      "5.8173686265945425e-05\n",
      "action_evaluation\n",
      "5.807623267173767e-05\n",
      "action_evaluation\n",
      "5.672365427017212e-05\n",
      "action_evaluation\n",
      "5.777716636657715e-05\n",
      "action_evaluation\n",
      "6.475627422332763e-05\n",
      "action_evaluation\n",
      "6.620734930038453e-05\n",
      "action_evaluation\n",
      "6.382703781127928e-05\n",
      "action_evaluation\n",
      "4.173547029495239e-05\n",
      "action_evaluation\n",
      "3.348514437675473e-05\n",
      "action_evaluation\n",
      "3.096386790275575e-05\n",
      "action_evaluation\n",
      "2.916976809501647e-05\n",
      "action_evaluation\n",
      "2.6526749134063725e-05\n",
      "action_evaluation\n",
      "2.3122727870941132e-05\n",
      "action_evaluation\n",
      "1.945495605468748e-05\n",
      "action_evaluation\n",
      "1.6074925661087097e-05\n",
      "action_evaluation\n",
      "1.2930780649185133e-05\n",
      "action_evaluation\n",
      "9.78797674179078e-06\n",
      "action_evaluation\n",
      "-7.6606869697576e-07\n",
      "action_evaluation\n",
      "-3.2755732536315875e-06\n",
      "action_evaluation\n",
      "-5.074739456176723e-06\n",
      "action_evaluation\n",
      "-6.732493638992383e-06\n",
      "action_evaluation\n",
      "-8.292943239212019e-06\n",
      "action_evaluation\n",
      "-9.805113077163727e-06\n",
      "action_evaluation\n",
      "-4.890412092208789e-06\n",
      "action_evaluation\n",
      "5.338191986083954e-06\n",
      "action_evaluation\n",
      "5.300045013427739e-06\n",
      "action_evaluation\n",
      "4.535913467407248e-06\n",
      "action_evaluation\n",
      "-2.7868151664734494e-06\n",
      "action_evaluation\n",
      "-6.16073608398441e-06\n",
      "action_evaluation\n",
      "-1.0108202695846536e-05\n",
      "action_evaluation\n",
      "-2.6595592498779286e-05\n",
      "action_evaluation\n",
      "-2.92134284973145e-05\n",
      "action_evaluation\n",
      "-2.806887030601499e-05\n",
      "action_evaluation\n",
      "-2.7299970388412525e-05\n",
      "action_evaluation\n",
      "-2.976894378662107e-05\n",
      "action_evaluation\n",
      "-3.9791464805603036e-05\n",
      "action_evaluation\n",
      "-3.885984420776365e-05\n",
      "action_evaluation\n",
      "-4.922807216644289e-05\n",
      "action_evaluation\n",
      "-4.5919418334960916e-05\n",
      "action_evaluation\n",
      "-4.2482316493988045e-05\n",
      "action_evaluation\n",
      "-4.4456869363784794e-05\n",
      "action_evaluation\n",
      "-6.683021783828735e-05\n",
      "action_evaluation\n",
      "-6.421148777008056e-05\n",
      "action_evaluation\n",
      "-5.833566188812255e-05\n",
      "action_evaluation\n",
      "-5.201846361160278e-05\n",
      "action_evaluation\n",
      "-4.5409500598907486e-05\n",
      "action_evaluation\n",
      "-3.739714622497559e-05\n",
      "action_evaluation\n",
      "-3.098756074905397e-05\n",
      "action_evaluation\n",
      "-3.080055117607119e-05\n",
      "action_evaluation\n",
      "-2.7943104505538934e-05\n",
      "action_evaluation\n",
      "-2.054393291473389e-05\n",
      "action_evaluation\n",
      "1.1637806892396971e-07\n",
      "action_evaluation\n",
      "4.7072768211364963e-07\n",
      "action_evaluation\n",
      "5.482435226440458e-06\n",
      "action_evaluation\n",
      "1.048535108566284e-05\n",
      "action_evaluation\n",
      "1.2480318546295125e-05\n",
      "action_evaluation\n",
      "1.9365102052688594e-05\n",
      "action_evaluation\n",
      "8.072704076766968e-06\n",
      "action_evaluation\n",
      "6.572008132934583e-06\n",
      "action_evaluation\n",
      "1.3105869293212897e-05\n",
      "action_evaluation\n",
      "4.771515727043153e-05\n",
      "action_evaluation\n",
      "2.3963749408721928e-05\n",
      "action_evaluation\n",
      "-1.1946260929107677e-05\n",
      "action_evaluation\n",
      "-2.0699352025985726e-05\n",
      "action_evaluation\n",
      "-1.9050985574722314e-05\n",
      "action_evaluation\n",
      "-2.151668071746825e-05\n",
      "action_evaluation\n",
      "-2.160206437110899e-05\n",
      "action_evaluation\n",
      "-1.8035471439361574e-05\n",
      "action_evaluation\n",
      "-1.4406442642211903e-05\n",
      "action_evaluation\n",
      "-8.028447628021277e-06\n",
      "action_evaluation\n",
      "-3.893673419952382e-06\n",
      "action_evaluation\n",
      "-8.84830951690689e-07\n",
      "action_evaluation\n",
      "1.990348100662227e-06\n",
      "action_evaluation\n",
      "4.988610744476301e-06\n",
      "action_evaluation\n",
      "8.167624473571762e-06\n",
      "action_evaluation\n",
      "2.239257097244265e-05\n",
      "action_evaluation\n",
      "4.457071423530579e-05\n",
      "Episode 3\tavg Score: 0.00"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def learn_a2c(n_episodes: int =  300, max_actions:int = 400 ):\n",
    "    scores = []\n",
    "    scores_window = deque(maxlen=100)\n",
    "    \n",
    "    \n",
    "    for i_episode in range(1,n_episodes+1):\n",
    "        \n",
    "        #reset the environment for every episode and initialize the state\n",
    "        #step_brain_info = env.reset(train_mode=i_episode % 100 != 0)[brain_name] # reset the environment\n",
    "        step_brain_info = env.reset(train_mode=True)[brain_name] # reset the environment\n",
    "        \n",
    "        \n",
    "        state = step_brain_info.vector_observations[0]   #obtain the starting state\n",
    "        \n",
    "        score = 0 #initialze the score for the episode\n",
    "        \n",
    "        \n",
    "        for a in range(max_actions):\n",
    "            action = agent.act(state)\n",
    "            \n",
    "            step_brain_info = env.step(action)[brain_name]\n",
    "            \n",
    "            next_state: np.ndarray = step_brain_info.vector_observations[0]   # get the next state\n",
    "            reward = step_brain_info.rewards[0]                   # get the reward\n",
    "            done = step_brain_info.local_done[0]                  # see if episode has finished\n",
    "            \n",
    "            score += reward\n",
    "            \n",
    "            agent.step(state, action, reward, next_state, done)\n",
    "            \n",
    "            state = next_state                             # roll over the state to next time step\n",
    "            if done:                             # exit loop if episode finished\n",
    "                break\n",
    "                \n",
    "            if env.global_done:\n",
    "                print('Global Done Steps: '+ str(a))\n",
    "                break\n",
    "        \n",
    "        scores.append(score)\n",
    "        scores_window.append(score)       # save most recent score\n",
    "        \n",
    "        print('\\rEpisode {}\\tavg Score: {:.2f}'.format(i_episode, np.mean(scores_window)), end=\"\")\n",
    "        if i_episode % 100 == 0:\n",
    "            print('\\rEpisode {}\\tavg Score: {:.2f}'.format(i_episode, np.mean(scores_window)))\n",
    "        if np.mean(scores_window)>=13.0:\n",
    "            print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)))\n",
    "            #torch.save(agent.qnetwork_local.state_dict(), 'checkpoint.pth')\n",
    "            break\n",
    "            \n",
    "    \n",
    "    return scores\n",
    "            \n",
    "    \n",
    "scores =  learn_a2c()\n",
    "# plot the scores\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(scores)), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show() \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the learned weights\n",
    "agent.save_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 500"
     ]
    }
   ],
   "source": [
    "# Train the critic and save the weights after training\n",
    "\n",
    "agent.restore_critic_weights()\n",
    "n_episodes = 500\n",
    "for i_episode in range(1,n_episodes+1):\n",
    "    \n",
    "    print('\\rEpisode ' + str(i_episode), end=\"\")\n",
    "    #reset the environment for every episode and initialize the state\n",
    "    #step_brain_info = env.reset(train_mode=i_episode % 100 != 0)[brain_name] # reset the environment\n",
    "    step_brain_info = env.reset(train_mode=True)[brain_name] # reset the environment\n",
    "    state = step_brain_info.vector_observations[0]   #obtain the starting state\n",
    "    \n",
    "    for a in range(500):\n",
    "        action = agent.act(state)\n",
    "            \n",
    "        step_brain_info = env.step(action)[brain_name]\n",
    "            \n",
    "        next_state: np.ndarray = step_brain_info.vector_observations[0]   # get the next state\n",
    "        reward = step_brain_info.rewards[0]                   # get the reward\n",
    "        done = step_brain_info.local_done[0]                  # see if episode has finished\n",
    "            \n",
    "        agent.train_critic(state, reward, next_state, done)\n",
    "            \n",
    "        state = next_state                             # roll over the state to next time step\n",
    "        if done:                             # exit loop if episode finished\n",
    "            break\n",
    "                \n",
    "        if env.global_done:\n",
    "            print('Global Done Steps: '+ str(a))\n",
    "            break\n",
    "    \n",
    "    \n",
    "\n",
    "agent.save_critic_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the trained agent in action\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drlnd",
   "language": "python",
   "name": "drlnd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
